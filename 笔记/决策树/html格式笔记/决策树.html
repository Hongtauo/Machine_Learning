<!DOCTYPE html>
<html lang="zh_CN" data-theme-mode="dark" data-light-theme="daylight" data-dark-theme="midnight">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"/>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="stylesheet" type="text/css" id="baseStyle" href="stage/build/export/base.css?2.7.6"/>
    <link rel="stylesheet" type="text/css" id="themeDefaultStyle" href="appearance/themes/midnight/theme.css?2.7.6"/>
    
    <title>C:\Users\Tao\Desktop\决策树 - 思源笔记  v2.7.6</title>
    <style>
        body {background-color: var(--b3-theme-background);color: var(--b3-theme-on-background)}
        .b3-typography, .protyle-wysiwyg, .protyle-title {font-size:16px !important}
.b3-typography code:not(.hljs), .protyle-wysiwyg span[data-type~=code] { font-variant-ligatures: none }
.li > .protyle-action {height:34px;line-height: 34px}
.protyle-wysiwyg [data-node-id].li > .protyle-action ~ .h1, .protyle-wysiwyg [data-node-id].li > .protyle-action ~ .h2, .protyle-wysiwyg [data-node-id].li > .protyle-action ~ .h3, .protyle-wysiwyg [data-node-id].li > .protyle-action ~ .h4, .protyle-wysiwyg [data-node-id].li > .protyle-action ~ .h5, .protyle-wysiwyg [data-node-id].li > .protyle-action ~ .h6 {line-height:34px;}
.protyle-wysiwyg [data-node-id].li > .protyle-action:after {height: 16px;width: 16px;margin:-8px 0 0 -8px}
.protyle-wysiwyg [data-node-id].li > .protyle-action svg {height: 14px}
.protyle-wysiwyg [data-node-id] [spellcheck] {min-height:26px;}
.protyle-wysiwyg [data-node-id] { text-align: justify;}
.protyle-wysiwyg .li {min-height:34px}
.protyle-gutters button svg {height:26px}
.protyle-wysiwyg img.emoji, .b3-typography img.emoji {width:18px}
.protyle-wysiwyg .h1 img.emoji, .b3-typography h1 img.emoji {width:35px}
.protyle-wysiwyg .h2 img.emoji, .b3-typography h2 img.emoji {width:31px}
.protyle-wysiwyg .h3 img.emoji, .b3-typography h3 img.emoji {width:27px}
.protyle-wysiwyg .h4 img.emoji, .b3-typography h4 img.emoji {width:25px}
.protyle-wysiwyg .h5 img.emoji, .b3-typography h5 img.emoji {width:22px}
.protyle-wysiwyg .h6 img.emoji, .b3-typography h6 img.emoji {width:20px}
    </style>
</head>
<body>
<div class="b3-typography" style="max-width: 800px;margin: 0 auto;" id="preview"><h1 id="决策树" updated="20230228174009">决策树</h1>
<p id="20230228174009-ofekud7" updated="20230228174009">决策树是一种基本的回归和分类方法，属于有监督学习。在学习的时候，决策树利用损失函数最小化原则建立决策树模型，在预测时根据新的数据运用决策树模型进行分类。决策树学习通常包括特征选择、决策树生成、决策树剪枝三个部分。</p>
<hr />
<h1 id="决策树模型" updated="20230228174009">决策树模型</h1>
<p id="20230228174009-parer6h" updated="20230228174009">分类决策树模型是一种描述对实例进行分类的树形结构，由结点和有向边组成。非叶子结点表示的是一个特征或者属性，叶子节点表示的是一个分类结果。</p>
<h2 id="if-then规则" updated="20230228174009">if-then规则</h2>
<p id="20230228174009-yej4it4" updated="20230228174009">决策树由根节点到叶子结点的每一条路径都是一条规则，其非叶子结点称作该路径上的规则，叶子结点表示的是该规则的分类结果，在决策树中，每一个实例有且仅被一条路径/规则所覆盖，这个性质称作互斥且完备。</p>
<h2 id="条件概率分布" updated="20230228174009">条件概率分布</h2>
<p id="20230228174009-77pbzax" updated="20230228174009">决策树还表示在给定特征下类的条件概率分布，这个条件概率分布定义在特征空间的划分上。在特征空间中将空间划分为两个不相交的区域，每个区域定义一个类的概率分布就构成了一个条件概率分布，如<span data-type="inline-math" data-subtype="math" data-content="P(A|B=b)" contenteditable="false" class="render-node"></span>表示的是在条件<span data-type="inline-math" data-subtype="math" data-content="B=b" contenteditable="false" class="render-node"></span>的区域下，类A的条件概率，如果在此条件<span data-type="inline-math" data-subtype="math" data-content="B=b" contenteditable="false" class="render-node"></span>区域下，类A由<span data-type="inline-math" data-subtype="math" data-content="A(a_1,a_2......a_n)" contenteditable="false" class="render-node"></span>组成，那么在分类时，决策树会将该结点的实例分配至条件概率大的那一个类中去，例如<span data-type="inline-math" data-subtype="math" data-content="A(a_1,a_2)" contenteditable="false" class="render-node"></span>，<span data-type="inline-math" data-subtype="math" data-content="P(A=a_1|B=b) > P(A=a_2|B=b)" contenteditable="false" class="render-node"></span>，那么，落入<span data-type="inline-math" data-subtype="math" data-content="b" contenteditable="false" class="render-node"></span>区域的实例在决策树中应该属于<span data-type="inline-math" data-subtype="math" data-content="a_1" contenteditable="false" class="render-node"></span>类。</p>
<p id="20230228174009-uq71he5" updated="20230228174009">示例：</p>
<blockquote id="20230228174009-uqhkv0m" updated="20230228174009">
<pre class="code-block" data-language=""><code class="hljs">             5%     包含违禁品
          /                    \
         /                      \
        /                        \
       /                          \
      /                            \
     /                              \
    /                                \
  99% 报警                         1% 不报警
     |                                |
     |                                |
     |                                |
  4.95% 包含违禁品且报警     0.05% 包含违禁品且不报警
                              /
                             /
                            /
                           /
                          /
                         /
                 95% 不包含违禁品
               /                \
              /                  \
             /                    \
            /                      \
           /                        \ 
         10% 报警                 90% 不报警
            |                        |
            |                        |
9.5% 不包含违禁品且报警    85.5% 不包含违禁品且不报警
</code></pre>
<p id="20230228174009-i5im9bx" updated="20230228174009">从决策树中，我们可以计算出一些条件概率分布，例如：</p>
<ul id="20230228174009-vibgsez" updated="20230228174009">
<li id="20230228174009-0fv5dzg" updated="20230228174009">
<p id="20230228174009-4uasdaw" updated="20230228174009">P(包含违禁品|报警) = P(包含违禁品且报警) ÷ P(报警) = (4.95%) ÷ (4.95% + 9.5%) ≈ <span data-type="strong">34.25%</span></p>
</li>
<li id="20230228174009-srwf2q6" updated="20230228174009">
<p id="20230228174009-yxewgs7" updated="20230228174009">P(不包含违禁品|不报警) = P(不包含违禁品且不报警) ÷ P(不报警) = (85.5%) ÷ (85.5% + 0.05%) ≈ <span data-type="strong">99.94%</span></p>
</li>
<li id="20230228174009-9ps1t9k" updated="20230228174009">
<p id="20230228174009-4ndtgfe" updated="20230228174009">P(不报警|包含违禁品) = P(包含违禁品且不报警) ÷ P(包含违禁品) = (0.05%) ÷(5%) = <span data-type="strong">1%</span></p>
</li>
</ul>
<p id="20230228174009-tyia2ny" updated="20230228174009">这样，我们就可以用决策树和条件概率分布来评估在安检时的各种情况和风险。</p>
<p id="20230228174009-0j9x3gn" updated="20230228174009">[来源:Newbing]</p>
</blockquote>
<h2 id="决策树学习" updated="20230228174009">决策树学习</h2>
<h3 id="特征选择" updated="20230228174009">特征选择</h3>
<p id="20230228174009-ndqg6fk" updated="20230228174009">特征选择在于选取对训练数据具有分类能力的特征，是决定用哪个特征来划分特征空间。</p>
<h4 id="信息增益" updated="20230228174009">信息增益</h4>
<h5 id="熵和条件熵" updated="20230228174009">熵和条件熵</h5>
<p id="20230228174009-grl2dj1" updated="20230228174009">熵表示的是随机变量的不确定性的度量，熵越大，不确定性越大</p>
<div data-content="H(x)=- \sum_{i=1}^{n} p(x) \log p(x)" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-ztuzy4e" updated="20230228174009">条件熵表示的是在已知的随机变量X的条件下随机变量Y的不确定性。随机变量X给定的条件下随机变量Y的条件熵<span data-type="inline-math" data-subtype="math" data-content="H(Y|X)" contenteditable="false" class="render-node"></span>定义为X给定条件下Y的条件概率分布的熵对X的数学期望</p>
<div data-content="H(Y|X)=\sum_{i=1}^{n}p_iH(Y|X=x_i)" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-566wyfk" updated="20230228174009">其中<span data-type="inline-math" data-subtype="math" data-content="p_i=P(X=x_i),i=1,2,3...n" contenteditable="false" class="render-node"></span>，<span data-type="inline-math" data-subtype="math" data-content="H(Y|X=x_i) 为X=x_i" contenteditable="false" class="render-node"></span>的样本子集</p>
<h5 id="信息增益-" updated="20230228174009">信息增益</h5>
<p id="20230228174009-icdzd0w" updated="20230228174009">表示得知特征X的信息而使得类Y的信息<span data-type="strong">不确定性减少的程度</span>，信息增益的定义如下，集合D的经验熵<span data-type="inline-math" data-subtype="math" data-content="H(D)" contenteditable="false" class="render-node"></span>与特征<span data-type="inline-math" data-subtype="math" data-content="A" contenteditable="false" class="render-node"></span>给定的条件下<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>的经验条件熵<span data-type="inline-math" data-subtype="math" data-content="H(D|A)" contenteditable="false" class="render-node"></span>之差。（也称作互信息）</p>
<div data-content="g(D,A)=H(D)-H(D|A)" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-gxqd7kj" updated="20230228174009">决策树学习中<span data-type="strong">使用信息增益准则作为特征选择的标准</span>，在给定的训练数据集<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>和特征<span data-type="inline-math" data-subtype="math" data-content="A" contenteditable="false" class="render-node"></span>中，经验熵<span data-type="inline-math" data-subtype="math" data-content="H(D)" contenteditable="false" class="render-node"></span>表示的是对数据集<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>进行分类的不确定性，经验条件熵<span data-type="inline-math" data-subtype="math" data-content="H(D|A)" contenteditable="false" class="render-node"></span>表示在特征A给定的条件下对数据集<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>进行分类的不确定性。<span data-type="strong">两者的差即为信息增益，信息增益大的特征具有更强的分类能力</span>。</p>
<p id="20230228174009-2bvg27t" updated="20230228174009">从公式中可以得到，信息增益大并不是说H(D)一定要大，而是说H(D|A)要比H(D)小很多，也就是说，特征A可以使得数据在给定A的条件下的熵降低很多。这样，数据就更加有序和纯净了，因为每个子集中同一类别的数据占比更高了。所以，信息增益大的特征可以更好地区分不同类别的数据，具有更强的分类能力。</p>
<h5 id="信息增益的算法" updated="20230228174009">信息增益的算法</h5>
<p id="20230228174009-apcrx4e" updated="20230228174009">给定数据集<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>和特征<span data-type="inline-math" data-subtype="math" data-content="A" contenteditable="false" class="render-node"></span>，假设数据集<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>由<span data-type="inline-math" data-subtype="math" data-content="k" contenteditable="false" class="render-node"></span>个类<span data-type="inline-math" data-subtype="math" data-content="C_k" contenteditable="false" class="render-node"></span>，特征A有n个不同的取值：<span data-type="inline-math" data-subtype="math" data-content="{a_1,a_2,a_3,...,a_n}" contenteditable="false" class="render-node"></span>，根据特征A划分的子集有<span data-type="inline-math" data-subtype="math" data-content="n" contenteditable="false" class="render-node"></span>个：<span data-type="inline-math" data-subtype="math" data-content="{D_1,D_2,...,D_n}" contenteditable="false" class="render-node"></span>，<span data-type="inline-math" data-subtype="math" data-content="D_i" contenteditable="false" class="render-node"></span>为子集中的其中一个，子集<span data-type="inline-math" data-subtype="math" data-content="D_i" contenteditable="false" class="render-node"></span>中属于类<span data-type="inline-math" data-subtype="math" data-content="C_k" contenteditable="false" class="render-node"></span>的样本集合记作<span data-type="inline-math" data-subtype="math" data-content="D_{ik}" contenteditable="false" class="render-node"></span></p>
<ul id="20230228174009-1z9cyc9" updated="20230228174009">
<li id="20230228174009-0c5cu9m" updated="20230228174009">
<p id="20230228174009-hnjhegv" updated="20230228174009">首先计算数据集<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>的信息增益熵<span data-type="inline-math" data-subtype="math" data-content="H(D)" contenteditable="false" class="render-node"></span></p>
<div data-content="H(D)=-\sum_{k=1}^{K}\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|}" data-subtype="math"><div spin="1"></div></div>
</li>
<li id="20230228174009-ifp1nfz" updated="20230228174009">
<p id="20230228174009-gma50rc" updated="20230228174009">其次计算特征<span data-type="inline-math" data-subtype="math" data-content="A" contenteditable="false" class="render-node"></span>对数据集<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>的条件经验熵<span data-type="inline-math" data-subtype="math" data-content="H(D|A)" contenteditable="false" class="render-node"></span></p>
<div data-content="H(D|A)=\sum_{n=1}^{n}H(D_i)=-\sum_{i=1}^{n}\frac{|D_i|}{|D|}\sum_{k=1}^{K}\frac{|C_{ik}|}{|D_i|}log_2\frac{|C_{ik}|}{|D_i|}" data-subtype="math"><div spin="1"></div></div>
</li>
<li id="20230228174009-q4cpunh" updated="20230228174009">
<p id="20230228174009-xzug4f6" updated="20230228174009">最后计算信息增益</p>
<div data-content="g(D,A)=H(D)-H(D|A)" data-subtype="math"><div spin="1"></div></div>
</li>
</ul>
<h4 id="信息增益比" updated="20230228174009">信息增益比</h4>
<p id="20230228174009-3ogau4i" updated="20230228174009">信息增益比的出现是为了校正信息增益值相对于训练数据集的大小问题，信息增益值的大小没有绝对的意义，通过比值的方式可以将其进行归一化</p>
<div data-content="g_R(D,A)=\frac{g(D,A)}{H(D)}" data-subtype="math"><div spin="1"></div></div>
<h3 id="决策树生成" updated="20230228174009">决策树生成</h3>
<p id="20230228174009-m8yapbk" updated="20230228174009">决策树生成的经典方法有ID3算法，C4.5算法，以及CART算法等</p>
<h4 id="ID3算法" updated="20230228174009">ID3算法</h4>
<p id="20230228174009-pbenqih" updated="20230228174009">ID3算法的核心是在决策树各个结点上应用信息增益准则选择特征，递归的构建决策树，算法过程如下：</p>
<ul id="20230228174009-cy6x0mv" updated="20230228174009">
<li id="20230228174009-yktkhuj" updated="20230228174009">
<p id="20230228174009-0soluhy" updated="20230228174009">从根节点开始，对所有可能的特征计算信息增益，选择信息增益最大的特征作为节点的划分标准，生成子节点。</p>
</li>
<li id="20230228174009-qqvev0h" updated="20230228174009">
<p id="20230228174009-28lvi4l" updated="20230228174009">对每个子节点，重复上述步骤，递归地构建决策树。</p>
</li>
<li id="20230228174009-yzavfus" updated="20230228174009">
<p id="20230228174009-a5c7dlt" updated="20230228174009">直到所有特征的信息增益都小于一个阈值或者没有特征可以选择为止。</p>
</li>
</ul>
<p id="20230228174009-yyrrtxa" updated="20230228174009">例子：</p>
<table id="20230228174009-gc8yxfn" updated="20230228174009">
<thead>
<tr>
<th align="center">RID</th>
<th>age</th>
<th>income</th>
<th>student</th>
<th>credit_rating</th>
<th>buy_compter</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">1</td>
<td>youth</td>
<td>high</td>
<td>no</td>
<td>fair</td>
<td>no</td>
</tr>
<tr>
<td align="center">2</td>
<td>youth</td>
<td>high</td>
<td>no</td>
<td>excellent</td>
<td>no</td>
</tr>
<tr>
<td align="center">3</td>
<td>middle_aged</td>
<td>high</td>
<td>no</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td align="center">4</td>
<td>senior</td>
<td>medium</td>
<td>no</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td align="center">5</td>
<td>senior</td>
<td>low</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td align="center">6</td>
<td>senior</td>
<td>low</td>
<td>yes</td>
<td>excellent</td>
<td>no</td>
</tr>
<tr>
<td align="center">7</td>
<td>middle_aged</td>
<td>low</td>
<td>yes</td>
<td>excellent</td>
<td>yes</td>
</tr>
<tr>
<td align="center">8</td>
<td>youth</td>
<td>medium</td>
<td>no</td>
<td>fair</td>
<td>no</td>
</tr>
<tr>
<td align="center">9</td>
<td>youth</td>
<td>low</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td align="center">10</td>
<td>senior</td>
<td>medium</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td align="center">11</td>
<td>youth</td>
<td>medium</td>
<td>yes</td>
<td>excellent</td>
<td>yes</td>
</tr>
<tr>
<td align="center">12</td>
<td>middle_aged</td>
<td>medium</td>
<td>no</td>
<td>excellent</td>
<td>yes</td>
</tr>
<tr>
<td align="center">13</td>
<td>middle_aged</td>
<td>high</td>
<td>yes</td>
<td>fair</td>
<td>yes</td>
</tr>
<tr>
<td align="center">14</td>
<td>senior</td>
<td>medium</td>
<td>no</td>
<td>excellent</td>
<td>no</td>
</tr>
</tbody>
</table>
<p id="20230228174009-od8vn7x" updated="20230228174009">[例题来源:<a href="https://www.cnblogs.com/liuming1992/p/4256007.html">ID3算法 - liuming_1992 - 博客园 (cnblogs.com)</a>]</p>
<h4 id="C4-5算法" updated="20230228174009">C4.5算法</h4>
<p id="20230228174009-259v5dv" updated="20230228174009">C4.5算法是一种生成决策树的经典算法，是ID3算法的一种延伸和优化。它的过程如下：</p>
<ul id="20230228174009-q2seifj" updated="20230228174009">
<li id="20230228174009-6hwpvwa" updated="20230228174009">
<p id="20230228174009-m4vg9ow" updated="20230228174009">从根节点开始，对所有可能的特征计算信息增益率，选择信息增益率最大的特征作为节点的划分标准，生成子节点。</p>
</li>
<li id="20230228174009-q29431x" updated="20230228174009">
<p id="20230228174009-hejsnwn" updated="20230228174009">对每个子节点，重复上述步骤，递归地构建决策树。</p>
</li>
<li id="20230228174009-2szl7jh" updated="20230228174009">
<p id="20230228174009-dh5wsxt" updated="20230228174009">直到所有特征的信息增益率都小于一个阈值或者没有特征可以选择为止。</p>
</li>
<li id="20230228174009-vszduas" updated="20230228174009">
<p id="20230228174009-olq77dz" updated="20230228174009">剪枝</p>
</li>
</ul>
<h4 id="CART算法" updated="20230228174009">CART算法</h4>
<p id="20230228174009-g0ubdj1" updated="20230228174009">CART算法，全称为Classification and Regression Tree，即分类与回归树。它是一种二分递归分割的技术，把当前样本划分为两个子样本，使得生成的每个非叶子结点都有两个分支，因此CART算法生成的决策树是结构简洁的二叉树。CART算法既可以用于分类任务，也可以用于回归任务。当CART用于分类任务时，采用基尼指数作为分裂节点的依据；当CART用于回归任务时，采用样本的最小方差作为分裂节点的依据。</p>
<p id="20230228174009-1xmddeu" updated="20230228174009">CART算法的步骤：</p>
<ul id="20230228174009-f5l40ed" updated="20230228174009">
<li id="20230228174009-mb25dls" updated="20230228174009">
<p id="20230228174009-5312pk1" updated="20230228174009">决策树生成：基于训练数据集生成决策树，生成的决策树和要尽量的大</p>
</li>
<li id="20230228174009-v31gc5e" updated="20230228174009">
<p id="20230228174009-n3ro221" updated="20230228174009">决策树剪枝：用验证数据集对已生成的树进行剪枝并且选择最优子树，这时用损失函数最小作为剪枝的标准</p>
</li>
</ul>
<blockquote id="20230228174009-i2vihzn" updated="20230228174009">
<p id="20230228174009-jhm3vtu" updated="20230228174009">训练集、测试集、验证集：</p>
<p id="20230228174009-1bsip5p" updated="20230228174009">训练集和测试集是机器学习中常用的两种数据集。训练集是用于训练模型的数据，测试集是用于评估模型的泛化能力的数据。</p>
<p id="20230228174009-u7qzxmf" updated="20230228174009">一般来说，我们会将原始数据按照一定的比例划分为训练集和测试集，比如80%的训练集和20%的测试集。这样可以保证模型在训练过程中不会接触到测试集，从而避免过拟合或欠拟合。</p>
<p id="20230228174009-iy411m4" updated="20230228174009">有时候，我们还会使用一个验证集，它是从训练集中分出来的一部分数据，用于调整模型的超参数或选择最优的模型。</p>
<p id="20230228174009-4zpprs3" updated="20230228174009">[来源：Newbing]</p>
</blockquote>
<p id="20230228174009-srvyjad" updated="20230228174009">CART和ID3的不同</p>
<ul id="20230228174009-ublic1w" updated="20230228174009">
<li id="20230228174009-7xg4v2d" updated="20230228174009">
<p id="20230228174009-yyqncj0" updated="20230228174009">二元划分：</p>
<p id="20230228174009-3srbvui" updated="20230228174009">二叉树不易产生数据碎片，精确度往往也会高于多叉树</p>
</li>
<li id="20230228174009-vrctflv" updated="20230228174009">
<p id="20230228174009-sc427n5" updated="20230228174009">CART中选择变量的不纯性度量：</p>
<ul id="20230228174009-yyn5tac" updated="20230228174009">
<li id="20230228174009-qgf16he" updated="20230228174009">
<p id="20230228174009-3o7ojl5" updated="20230228174009">分类目标：Gini指标、Towing、order Towing</p>
</li>
<li id="20230228174009-55n13wp" updated="20230228174009">
<p id="20230228174009-ctgcg6g" updated="20230228174009">连续目标：最小平方残差、最小绝对残差</p>
</li>
</ul>
</li>
<li id="20230228174009-8kx4m5b" updated="20230228174009">
<p id="20230228174009-3qmd194" updated="20230228174009">剪枝：</p>
<p id="20230228174009-8ehvrm7" updated="20230228174009">用预剪枝或后剪枝对训练集生长的树进行剪枝</p>
</li>
<li id="20230228174009-iq9a38j" updated="20230228174009">
<p id="20230228174009-g7c9vqa" updated="20230228174009">树的建立：</p>
<ul id="20230228174009-fql8yme" updated="20230228174009">
<li id="20230228174009-cl3pqrk" updated="20230228174009">
<p id="20230228174009-ame748f" updated="20230228174009">如果目标变量是标称的，并且是具有两个以上的类别，则CART可能考虑将目标类别合并成两个超类别（双化）；</p>
</li>
<li id="20230228174009-m5n8aam" updated="20230228174009">
<p id="20230228174009-n35g41y" updated="20230228174009">如果目标变量是连续的，则CART算法找出一组基于树的回归方程来预测目标变量。</p>
</li>
</ul>
</li>
</ul>
<h5 id="CART生成" updated="20230228174009">CART生成</h5>
<p id="20230228174009-zdjrpbl" updated="20230228174009">决策树的生成就是递归的构建二叉决策树的过程。</p>
<h5 id="分类树" updated="20230228174009">分类树</h5>
<h6 id="基尼指数" updated="20230228174009">基尼指数</h6>
<p id="20230228174009-p8o35c1" updated="20230228174009">分类树采用的是基尼指数选择最优特征，同时决定该特征的最优二值切分点。</p>
<div data-content="Gini(p) = 1 - \sum_{k=1}^{K}p_k(1-p_k)=1 - \sum_{k=1}^{K}p_k^2" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-kapgwf8" updated="20230228174009">对于二分类问题，若样本点属于第1个类的概率是<span data-type="inline-math" data-subtype="math" data-content="p" contenteditable="false" class="render-node"></span>，则概率分布的基尼指数为</p>
<div data-content="Gini(p)=2p(1-p)" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-88wg33u" updated="20230228174009">对于给定的样本集合<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>，其基尼指数为：</p>
<div data-content="Gini(p)=1-\sum_{k-1}^{k}(\frac{|C_k|}{|D|})^2" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-z0hcc6n" updated="20230228174009">这里<span data-type="inline-math" data-subtype="math" data-content="C_k" contenteditable="false" class="render-node"></span>是<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>中属于第<span data-type="inline-math" data-subtype="math" data-content="k" contenteditable="false" class="render-node"></span>类的样本子集，K是类的个数</p>
<p id="20230228174009-d0odv2h" updated="20230228174009">如果样本集合D根据特征A是否可以取某一可能值a被分割为<span data-type="inline-math" data-subtype="math" data-content="D_1" contenteditable="false" class="render-node"></span>和<span data-type="inline-math" data-subtype="math" data-content="D_2" contenteditable="false" class="render-node"></span>两部分，即</p>
<div data-content="D_1=\left \{ (x,y)∈ D| A(x) = a \right \} , D_2=D-D_1" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-g8a3x20" updated="20230228174009">则在特征A的条件下，集合D的基尼指数定义为</p>
<div data-content="Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-glw072h" updated="20230228174009">基尼指数<span data-type="inline-math" data-subtype="math" data-content="Gini(D)" contenteditable="false" class="render-node"></span>表示集合<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>的不确定性，基尼指数<span data-type="inline-math" data-subtype="math" data-content="Gini(D,A)" contenteditable="false" class="render-node"></span>表示经过<span data-type="inline-math" data-subtype="math" data-content="A=a" contenteditable="false" class="render-node"></span>分割后集合D的不确定性，基尼指数越大，样本集合的不确定性也就越大</p>
<p id="20230228174009-rik5gdv" updated="20230228174009"><span class="img" style="display: block; max-width: 382px;"><img src="assets/image-20230226151909-9l29j0h.png" alt="image" style="width: 372px;" parent-style="display: block; max-width: 382px;" /></span></p>
<h6 id="CART生成算法" updated="20230228174009">CART生成算法</h6>
<p id="20230228174009-4p3aswq" updated="20230228174009">根据训练数据集，从根结点开始，递归地对每个结点进行以下操作，构建二叉决策树：</p>
<p id="20230228174009-krhjzwr" updated="20230228174009">输入：训练数据集D，停止计算条件</p>
<p id="20230228174009-w47wr0s" updated="20230228174009">输出：CART决策树</p>
<ul id="20230228174009-t3v8h4w" updated="20230228174009">
<li id="20230228174009-uhwe2gf" updated="20230228174009">
<p id="20230228174009-62s51rf" updated="20230228174009">设结点的训练数据集为D，计算现有特征对该数据集的基尼指数。此时，对<span data-type="strong">每一个特征</span>A，对其<span data-type="strong">可能取的每个值</span>a，根据样本点对A=a的测试为&quot;是&quot;或&quot;否&quot;将<span data-type="inline-math" data-subtype="math" data-content="D" contenteditable="false" class="render-node"></span>分割成 <span data-type="inline-math" data-subtype="math" data-content="D_1" contenteditable="false" class="render-node"></span>和<span data-type="inline-math" data-subtype="math" data-content="D_2" contenteditable="false" class="render-node"></span> 两部分，利用公式<span data-type="inline-math" data-subtype="math" data-content="Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)" contenteditable="false" class="render-node"></span>计算<span data-type="inline-math" data-subtype="math" data-content="A=a" contenteditable="false" class="render-node"></span>时的基尼指数。</p>
</li>
<li id="20230228174009-2h5f7d5" updated="20230228174009">
<p id="20230228174009-33tw611" updated="20230228174009">在所有可能的特征A以及它们所有可能的切分点a中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依最优特征与最优切分点，从现结点生成两个子结点，将训练数据集依特征分配到两个子结点中去。</p>
</li>
<li id="20230228174009-ross7rw" updated="20230228174009">
<p id="20230228174009-6zw86n0" updated="20230228174009">对两个子结点递归地调用(1)，(2)，直至满足停止条件。</p>
</li>
<li id="20230228174009-lqbggtu" updated="20230228174009">
<p id="20230228174009-pe03ak2" updated="20230228174009">生成CART决策树。</p>
</li>
</ul>
<p id="20230228174009-kyqwsay" updated="20230228174009"><span data-type="strong">算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于预定阈值(样本基本属于同一类)，或者没有更多特征。</span></p>
<h6 id="例题" updated="20230228174009">例题</h6>
<p id="20230228174009-jifsthl" updated="20230228174009">根据下表建立一棵决策树</p>
<table id="20230228174009-pw2cxg7" updated="20230228174009">
<thead>
<tr>
<th>ID</th>
<th>年龄（A1）</th>
<th>有工作（A2）</th>
<th>有自己的房子(A3)</th>
<th>信贷情况(A4)</th>
<th>类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>否</td>
</tr>
<tr>
<td>3</td>
<td>青年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>4</td>
<td>青年</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">是</span></td>
<td>一般</td>
<td>是</td>
</tr>
<tr>
<td>5</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>6</td>
<td>中年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>中年</td>
<td>否</td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>否</td>
</tr>
<tr>
<td>8</td>
<td>中年</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">是</span></td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>9</td>
<td>中年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>10</td>
<td>中年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>11</td>
<td>老年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>12</td>
<td>老年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>13</td>
<td>老年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>14</td>
<td>老年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>15</td>
<td>老年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
</tbody>
</table>
<ul id="20230228174009-04fid31" updated="20230228174009">
<li id="20230228174009-3k99rcg" updated="20230228174009">
<p id="20230228174009-49ot610" updated="20230228174009"><span data-type="strong">首先，求基尼指数</span></p>
<ul id="20230228174009-38qwhgh" updated="20230228174009">
<li id="20230228174009-ga0z3oj" updated="20230228174009">
<p id="20230228174009-hmm2cuq" updated="20230228174009"><span data-type="strong">对于</span><span data-type="inline-math strong" data-subtype="math" data-content="A_1" contenteditable="false" class="render-node"></span>（1 表示青年 ，2 表示中年，3 表示老年）</p>
<p id="20230228174009-g1bq1mr" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D,A_1=1)=\frac{5}{15}*(2*\frac{2}{5}*(1-\frac{2}{5}))+\frac{10}{15}*(2*\frac{7}{10}*(1-\frac{7}{10}))=0.44" contenteditable="false" class="render-node"></span></p>
<p id="20230228174009-skzmubk" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D,A_1=2)=\frac{5}{15}*(2*\frac{3}{5}*(1-\frac{3}{5}))+\frac{10}{15}*(2*\frac{6}{10}*(1-\frac{6}{10}))=0.48" contenteditable="false" class="render-node"></span>​</p>
<p id="20230228174009-7az20ag" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D,A_1=3)=\frac{5}{15}*(2*\frac{4}{5}*(1-\frac{4}{5}))+\frac{10}{15}*(2*\frac{5}{10}*(1-\frac{5}{10}))=0.44" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-kwf5cp9" updated="20230228174009">
<p id="20230228174009-5dndclu" updated="20230228174009"><span data-type="strong">对于</span><span data-type="inline-math strong" data-subtype="math" data-content="A_2" contenteditable="false" class="render-node"></span>（1表示是，2表示否）</p>
<p id="20230228174009-gyehg5z" updated="20230228174009"><span data-type="inline-math mark" data-subtype="math" data-content="Gini(D,A_2=1)=\frac{5}{15}*(2*\frac{5}{5}*(1-\frac{5}{5}))+\frac{10}{15}*(2*\frac{4}{10}*(1-\frac{4}{10}))=0.32" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-kqtvn57" updated="20230228174009">
<p id="20230228174009-iutbui1" updated="20230228174009"><span data-type="strong">对于</span><span data-type="inline-math strong" data-subtype="math" data-content="A_3" contenteditable="false" class="render-node"></span>（1表示是，2表示否）</p>
<p id="20230228174009-3dq9osa" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D,A_3=1)=\frac{6}{15}*(2*\frac{6}{6}*(1-\frac{6}{6}))+\frac{9}{15}*(2*\frac{3}{9}*(1-\frac{3}{9}))=0.27" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-ywmypfa" updated="20230228174009">
<p id="20230228174009-rgmhupf" updated="20230228174009"><span data-type="strong">对于</span><span data-type="inline-math strong" data-subtype="math" data-content="A_4" contenteditable="false" class="render-node"></span>（1 表示非常好 ，2 表示好，3 表示一般）</p>
<p id="20230228174009-r7itfv9" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D,A_4=1)=\frac{4}{15}*(2*\frac{0}{4}*(1-\frac{4}{4}))+\frac{11}{15}*(2*\frac{5}{11}*(1-\frac{5}{11}))=0.36" contenteditable="false" class="render-node"></span></p>
<p id="20230228174009-a97a5g6" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D,A_4=2)=\frac{6}{15}*(2*\frac{4}{6}*(1-\frac{4}{6}))+\frac{9}{15}*(2*\frac{5}{9}*(1-\frac{5}{9}))=0.47" contenteditable="false" class="render-node"></span></p>
<p id="20230228174009-kbm94uc" updated="20230228174009"><span data-type="inline-math mark" data-subtype="math" data-content="Gini(D,A_4=3)=0.32" contenteditable="false" class="render-node"></span></p>
</li>
</ul>
<p id="20230228174009-68vmhxj" updated="20230228174009"><span data-type="strong">取基尼指数最小的特征作为最优特征，在最优特征中选择基尼系数最小的点作为最优切分点</span></p>
</li>
<li id="20230228174009-752yoyg" updated="20230228174009">
<p id="20230228174009-alp647i" updated="20230228174009">第一次切分：最优特征：<span data-type="inline-math" data-subtype="math" data-content="A_3" contenteditable="false" class="render-node"></span>，最优切分点：<span data-type="inline-math" data-subtype="math" data-content="A_3=1" contenteditable="false" class="render-node"></span></p>
<ul id="20230228174009-vd85uql" updated="20230228174009">
<li id="20230228174009-wec3ess" updated="20230228174009">
<p id="20230228174009-p5hs1uc" updated="20230228174009"><span data-type="inline-math strong" data-subtype="math" data-content="D_1：" contenteditable="false" class="render-node"></span><span data-type="strong">有自己的房子</span></p>
<table id="20230228174009-vcx9ahk" updated="20230228174009">
<thead>
<tr>
<th>ID</th>
<th>年龄（A1）</th>
<th>有工作（A2）</th>
<th>有自己的房子(A3)</th>
<th>信贷情况(A4)</th>
<th>类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>青年</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">是</span></td>
<td>一般</td>
<td>是</td>
</tr>
<tr>
<td>8</td>
<td>中年</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">是</span></td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>9</td>
<td>中年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>10</td>
<td>中年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>11</td>
<td>老年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>12</td>
<td>老年</td>
<td>否</td>
<td><span data-type="mark">是</span></td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
</tbody>
</table>
<p id="20230228174009-33f2520" updated="20230228174009">由于类别以及全为同一类“是”，无需继续切分，已到达最优，算法停止</p>
</li>
<li id="20230228174009-y9de6jy" updated="20230228174009">
<p id="20230228174009-82ol9vs" updated="20230228174009"><span data-type="inline-math strong" data-subtype="math" data-content="D_2：" contenteditable="false" class="render-node"></span><span data-type="strong">没有自己的房子</span></p>
<table id="20230228174009-7jv8htn" updated="20230228174009">
<thead>
<tr>
<th>ID</th>
<th>年龄（A1）</th>
<th>有工作（A2）</th>
<th>有自己的房子(A3)</th>
<th>信贷情况(A4)</th>
<th>类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>否</td>
</tr>
<tr>
<td>3</td>
<td>青年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>5</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>6</td>
<td>中年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>中年</td>
<td>否</td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>否</td>
</tr>
<tr>
<td>13</td>
<td>老年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>14</td>
<td>老年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
<tr>
<td>15</td>
<td>老年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
</tbody>
</table>
<ul id="20230228174009-8nbbrqf" updated="20230228174009">
<li id="20230228174009-oh10ldm" updated="20230228174009">
<p id="20230228174009-5cj5u3a" updated="20230228174009">对于A1</p>
<ul id="20230228174009-9pu5szz" updated="20230228174009">
<li id="20230228174009-t2ppkuf" updated="20230228174009">
<p id="20230228174009-r66zav4" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_1=1)=\frac{4}{9}*(2*\frac{1}{4}*(1-\frac{1}{4}))+\frac{5}{9}*(2*\frac{2}{5}*(1-\frac{2}{5}))=0.43" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-u9wtn8b" updated="20230228174009">
<p id="20230228174009-ah8bm8b" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_1=2)=\frac{2}{9}*(2*\frac{0}{2}*(1-\frac{0}{2}))+\frac{6}{9}*(2*\frac{3}{6}*(1-\frac{3}{6}))=0.33" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-8yezy16" updated="20230228174009">
<p id="20230228174009-0qaekxm" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_1=3)=\frac{3}{9}*(2*\frac{2}{3}*(1-\frac{2}{3}))+\frac{6}{9}*(2*\frac{1}{6}*(1-\frac{1}{6}))=0.33" contenteditable="false" class="render-node"></span></p>
</li>
</ul>
</li>
<li id="20230228174009-vf4sohv" updated="20230228174009">
<p id="20230228174009-45cld8p" updated="20230228174009">对于A2</p>
<ul id="20230228174009-zifc78b" updated="20230228174009">
<li id="20230228174009-i6n5i31" updated="20230228174009">
<p id="20230228174009-go67uvw" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_2=1)=\frac{3}{9}*(2*\frac{3}{3}*(1-\frac{3}{3}))+\frac{6}{9}*(2*\frac{0}{6}*(1-\frac{0}{6}))=0" contenteditable="false" class="render-node"></span></p>
<p id="20230228174009-r75nz38" updated="20230228174009">Gini值为0，<span data-type="strong">必定是最小结点</span>，则取基尼系数最小的特征A2作为最优特征进行划分</p>
<ul id="20230228174009-0i126y8" updated="20230228174009">
<li id="20230228174009-tfqkoyw" updated="20230228174009">
<p id="20230228174009-4q2x7rs" updated="20230228174009"><span data-type="inline-math strong" data-subtype="math" data-content="D_{21}：" contenteditable="false" class="render-node"></span><span data-type="strong">有工作</span></p>
<table id="20230228174009-i5ncxo8" updated="20230228174009">
<thead>
<tr>
<th>ID</th>
<th>年龄（A1）</th>
<th>有工作（A2）</th>
<th>有自己的房子(A3)</th>
<th>信贷情况(A4)</th>
<th>类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>3</td>
<td>青年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>13</td>
<td>老年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>是</td>
</tr>
<tr>
<td>14</td>
<td>老年</td>
<td><span data-type="mark">是</span></td>
<td>否</td>
<td><span data-type="mark">非常好</span></td>
<td>是</td>
</tr>
</tbody>
</table>
<p id="20230228174009-itvd9of" updated="20230228174009"><span data-type="strong">有工作</span>，类别以及全为同一类“是”，无需继续切分，已到达最优，算法停止</p>
</li>
<li id="20230228174009-bq9ke9x" updated="20230228174009">
<p id="20230228174009-lysmsao" updated="20230228174009"><span data-type="inline-math strong" data-subtype="math" data-content="D_{22}：" contenteditable="false" class="render-node"></span><span data-type="strong">没工作</span></p>
<table id="20230228174009-9jazv8b" updated="20230228174009">
<thead>
<tr>
<th>ID</th>
<th>年龄（A1）</th>
<th>有工作（A2）</th>
<th>有自己的房子(A3)</th>
<th>信贷情况(A4)</th>
<th>类别</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>否</td>
</tr>
<tr>
<td>5</td>
<td>青年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>6</td>
<td>中年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
<tr>
<td>7</td>
<td>中年</td>
<td>否</td>
<td>否</td>
<td><span data-type="em">好</span></td>
<td>否</td>
</tr>
<tr>
<td>15</td>
<td>老年</td>
<td>否</td>
<td>否</td>
<td>一般</td>
<td>否</td>
</tr>
</tbody>
</table>
<p id="20230228174009-yo8ebzy" updated="20230228174009"><span data-type="strong">没工作</span>，类别以及全为同一类“是”，无需继续切分，已到达最优，算法停止</p>
</li>
</ul>
</li>
</ul>
</li>
<li id="20230228174009-9mvduzk" updated="20230228174009">
<p id="20230228174009-iqc2ver" updated="20230228174009">对于A3</p>
<ul id="20230228174009-1mrnxlr" updated="20230228174009">
<li id="20230228174009-vpgd89o" updated="20230228174009">
<p id="20230228174009-weufsv9" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_3=1)=\frac{0}{9}*(2*\frac{0}{0}*(1-\frac{0}{0}))+\frac{9}{9}*(2*\frac{3}{9}*(1-\frac{3}{9}))=0.45" contenteditable="false" class="render-node"></span></p>
</li>
</ul>
</li>
<li id="20230228174009-5lz0ozz" updated="20230228174009">
<p id="20230228174009-9mlm29n" updated="20230228174009">对于A4</p>
<ul id="20230228174009-h2dgwf4" updated="20230228174009">
<li id="20230228174009-4yhnzf4" updated="20230228174009">
<p id="20230228174009-ionuve8" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_4=1)=\frac{1}{9}*(2*\frac{1}{1}*(1-\frac{1}{1}))+\frac{8}{9}*(2*\frac{2}{8}*(1-\frac{2}{8}))=0.33" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-37yhr3a" updated="20230228174009">
<p id="20230228174009-ds3srni" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_4=2)=\frac{4}{9}*(2*\frac{2}{4}*(1-\frac{2}{4}))+\frac{5}{9}*(2*\frac{1}{5}*(1-\frac{1}{5}))=0.40" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-g8qg96o" updated="20230228174009">
<p id="20230228174009-oc07hch" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="Gini(D_{2},A_4=3)=\frac{4}{9}*(2*\frac{0}{4}*(1-\frac{0}{4}))+\frac{5}{9}*(2*\frac{3}{5}*(1-\frac{3}{5}))=0.27" contenteditable="false" class="render-node"></span></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li id="20230228174009-w82jm4y" updated="20230228174009">
<p id="20230228174009-fhxoz6f" updated="20230228174009"><span data-type="strong">算法结束，决策树如下：</span></p>
<p id="20230228174009-z23t7cd" updated="20230228174009"><span class="img" style="display: block;"><img src="assets/图表1-20230227172649-06afe6b.png" alt="图表1" parent-style="display: block;" /></span></p>
</li>
</ul>
<p id="20230228174009-avv920c" updated="20230228174009">​​</p>
<h5 id="回归树" updated="20230228174009">回归树</h5>
<p id="20230228174009-f6i8btz" updated="20230228174009">决策树的生成就是递归地构建二叉决策树的过程，对回归树用平方误差最小化准则，进行特征选择，生成二叉树。</p>
<h6 id="最小二乘法" updated="20230228174009">最小二乘法</h6>
<blockquote id="20230228174009-xhopmnm" updated="20230228174009">
<p id="20230228174009-kjlnf82" updated="20230228174009">最小二乘法是一种数学优化建模方法，它通过最小化误差的平方和寻找数据的最佳函数匹配。最小二乘法的主要思想是通过确定未知参数（通常是一个参数矩阵），来使得真实值和预测值的误差（也称残差）平方和最小。最小二乘法可以用于线性回归、曲线拟合等问题。</p>
</blockquote>
<h6 id="输入空间的划分" updated="20230228174009">输入空间的划分</h6>
<p id="20230228174009-cnbh5qq" updated="20230228174009">假设<span data-type="inline-math" data-subtype="math" data-content="X" contenteditable="false" class="render-node"></span>与<span data-type="inline-math" data-subtype="math" data-content="Y" contenteditable="false" class="render-node"></span>分别为输入和输出变量，并且<span data-type="inline-math" data-subtype="math" data-content="Y" contenteditable="false" class="render-node"></span>是连续变量，给定训练数据集</p>
<div data-content="D={(x_1,y_1),(x_2,y_2),...,(x_n,y_n)}" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-7lw0pd1" updated="20230228174009">考虑如何生成回归树。</p>
<p id="20230228174009-49bqnsd" updated="20230228174009">一个回归树对印的是对输入空间（特征空间）的一个划分，以及在划分的单元上的输出值。假设对输入空间的划分为<span data-type="inline-math" data-subtype="math" data-content="M" contenteditable="false" class="render-node"></span>个单元格<span data-type="inline-math" data-subtype="math" data-content="R_1,R_2......,R_M" contenteditable="false" class="render-node"></span>，在每个单元格<span data-type="inline-math" data-subtype="math" data-content="R_m" contenteditable="false" class="render-node"></span>上有一个固定的输出值<span data-type="inline-math" data-subtype="math" data-content="c_m" contenteditable="false" class="render-node"></span>，于是回归树模型可以表示为</p>
<div data-content="f(x)=\sum_{m=1}^{M}c_mI(x∈R_m)" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-u9l5bri" updated="20230228174009">当输入空间的划分确定的时候，可以使用平方误差<span data-type="inline-math" data-subtype="math" data-content="\sum_{x_i{∈R_m}} (y_i - f(x_i))^2" contenteditable="false" class="render-node"></span>来表示回归树对于训练数据的预测误差，用<span data-type="strong">平方误差最小</span>的准则求解每个单元上最优输出值。</p>
<p id="20230228174009-60m0ps0" updated="20230228174009">同时，我们可以得知，单元<span data-type="inline-math" data-subtype="math" data-content="R_m" contenteditable="false" class="render-node"></span>上的<span data-type="inline-math" data-subtype="math" data-content="C_m" contenteditable="false" class="render-node"></span>的最优值<span data-type="inline-math" data-subtype="math" data-content="\hat{c_m}" contenteditable="false" class="render-node"></span>是<span data-type="inline-math" data-subtype="math" data-content="R_m" contenteditable="false" class="render-node"></span>上所有输入实例<span data-type="inline-math" data-subtype="math" data-content="x_i" contenteditable="false" class="render-node"></span>所对应的输出<span data-type="inline-math" data-subtype="math" data-content="y_i" contenteditable="false" class="render-node"></span>的<span data-type="strong">均值</span>，即</p>
<div data-content="\hat{c_m}=ave(y_i|x_i∈R_m)" data-subtype="math"><div spin="1"></div></div>
<blockquote id="20230228174009-698syti" updated="20230228174009">
<p id="20230228174009-ddko5ua" updated="20230228174009">回归树的学习过程是将数据集划分成若干个单元（叶子节点），每个单元对应一个区域<span data-type="inline-math" data-subtype="math" data-content="r_m" contenteditable="false" class="render-node"></span>和一个常数<span data-type="inline-math" data-subtype="math" data-content="c_m" contenteditable="false" class="render-node"></span>。<span data-type="inline-math" data-subtype="math" data-content="c_m" contenteditable="false" class="render-node"></span>表示该区域内所有数据点的输出值的预测。</p>
<p id="20230228174009-0kx7rsu" updated="20230228174009">为了找到最优的<span data-type="inline-math" data-subtype="math" data-content="c_m" contenteditable="false" class="render-node"></span>，我们需要最小化每个单元上的平方误差损失函数：</p>
<div data-content="\sum_{x_i \in r_m}(y_i - c_m)^2" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-l8dle6j" updated="20230228174009">这个损失函数关于<span data-type="inline-math" data-subtype="math" data-content="c_m" contenteditable="false" class="render-node"></span>求导，并令其等于零，得到：</p>
<div data-content="c_m = \frac{1}{N_m}\sum_{x_i \in r_m}y_i" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-l4dbae3" updated="20230228174009">其中<span data-type="inline-math" data-subtype="math" data-content="N_m" contenteditable="false" class="render-node"></span>表示<span data-type="inline-math" data-subtype="math" data-content="r_m" contenteditable="false" class="render-node"></span>中数据点的个数。这就意味着<span data-type="inline-math" data-subtype="math" data-content="c_m" contenteditable="false" class="render-node"></span>是<span data-type="inline-math" data-subtype="math" data-content="r_m" contenteditable="false" class="render-node"></span>上所有输入实例<span data-type="inline-math" data-subtype="math" data-content="x_i" contenteditable="false" class="render-node"></span>所对应的输出<span data-type="inline-math" data-subtype="math" data-content="y_i" contenteditable="false" class="render-node"></span>的均值。</p>
<p id="20230228174009-uiko2o5" updated="20230228174009">换句话说，回<span data-type="strong">归树通过取平均值来预测每个区域内数据点的输出值除了取平均值，这也符合直觉，因为取均值可以使得平方误差最小。</span>，还有一种回归树叫做模型树(model tree)。模型树是在每个区域内拟合一个线性回归模型来预测输出值。这样可以提高预测的精度和灵活性，但也增加了计算的复杂度。</p>
<p id="20230228174009-rfrjodm" updated="20230228174009">[来源：Newbing]</p>
</blockquote>
<p id="20230228174009-frljg7i" updated="20230228174009">问题是，怎样对输入空间进行划分，这这里采用启发式的方法，选择第j个变量<span data-type="inline-math" data-subtype="math" data-content="x^{(j)}" contenteditable="false" class="render-node"></span>和他的取值s，作为切分变量和切分点，同时定义两个区域<span data-type="inline-math" data-subtype="math" data-content="R_1" contenteditable="false" class="render-node"></span>和<span data-type="inline-math" data-subtype="math" data-content="R_2" contenteditable="false" class="render-node"></span>：</p>
<div data-content="R_{1}(j,s)=\left \{x|x^{(j)}≤s  \right \}  \ \ \ 和\ \ \ R_{2}(j,s)=\left \{x|x^{(j)}&gt;s  \right \}" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-4903yky" updated="20230228174009">然后寻找最优切分变量<span data-type="inline-math" data-subtype="math" data-content="j" contenteditable="false" class="render-node"></span>和最优切分点<span data-type="inline-math" data-subtype="math" data-content="s" contenteditable="false" class="render-node"></span>，也就是求解：</p>
<div data-content="\min_{j,s} \left [ \min_{c_1} \sum_{x_i∈R_1(j,s)}(y_i-c_i)^2+\min_{c_2}\sum_{x_i∈R_2(j,s)}(y_j-c_2)^2 \right ]" data-subtype="math"><div spin="1"></div></div>
<blockquote id="20230228174009-lm5rhui" updated="20230228174009">
<p id="20230228174009-o0dto5w" updated="20230228174009">如何理解这个公式：</p>
<p id="20230228174009-xpq32tk" updated="20230228174009">首先我们要确定，我们如何找到最优切分变量与最优切分点？首先是确定损失函数，在此我们使用平方误差损失函数去度量切分变量与切分点的选择，我们通过对平方误差损失函数取<span data-type="inline-math" data-subtype="math" data-content="min" contenteditable="false" class="render-node"></span>，即对损失函数求导，并让其等于零</p>
<div data-content="\frac{\partial}{\partial c_m}\sum_{x_i \in r_m}(y_i - c_m)^2= \sum_{x_i \in r_m}\frac{\partial}{\partial c_m}(y_i - c_m)^2" data-subtype="math"><div spin="1"></div></div>
<div data-content="= \sum_{x_i \in r_m}2(y_i - c_m)\frac{\partial}{\partial c_m}(y_i - c_m)" data-subtype="math"><div spin="1"></div></div>
<div data-content="= \sum_{x_i \in r_m}2(y_i - c_m)(-1)" data-subtype="math"><div spin="1"></div></div>
<div data-content="= -2\sum_{x_i \in r_m}(y_i - c_m)" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-8cg0is0" updated="20230228174009">令其等于零，得到：</p>
<div data-content="-2\sum_{x_i \in r_m}(y_i - c_m) = 0" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-w35a7ur" updated="20230228174009">移项，得到：</p>
<div data-content="\sum_{x_i \in r_m}y_i = N_mc_m" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-qwwwbm3" updated="20230228174009">除以<span data-type="inline-math" data-subtype="math" data-content="N_m" contenteditable="false" class="render-node"></span>，得到：</p>
<div data-content="c_m = \frac{1}{N_m}\sum_{x_i \in r_m}y_i" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-kz29m6f" updated="20230228174009">对于两类问题也是如此，<span data-type="strong">在固定一个最优变量j的情况下，考察所有的切分点s，然后对于所有的最优变量j进行考察，最终选出最优变量与切分点，与分类树的过程是类似的。这里的考察指的是最小化损失函数</span>。也就是说对于两类问题，只不过<span data-type="strong">损失函数不同</span>。在<span data-type="strong">固定一个</span>切分变量<span data-type="inline-math" data-subtype="math" data-content="j" contenteditable="false" class="render-node"></span>的情况下，<span data-type="strong">考察所有可能的切分点</span><span data-type="inline-math strong" data-subtype="math" data-content="s" contenteditable="false" class="render-node"></span>，然后计算每种划分方式下损失函数的大小，并选择最小化损失函数的切分点<span data-type="inline-math" data-subtype="math" data-content="s^*" contenteditable="false" class="render-node"></span>。然后对所有可能的切分变量<span data-type="inline-math" data-subtype="math" data-content="j" contenteditable="false" class="render-node"></span>进行考察，并选择最小化损失函数的切分变量<span data-type="inline-math" data-subtype="math" data-content="j" contenteditable="false" class="render-node"></span>​。这样就可以得到最优切分变量和最优切分点<span data-type="inline-math" data-subtype="math" data-content="(j^*, s^*)" contenteditable="false" class="render-node"></span>。</p>
</blockquote>
<p id="20230228174009-lp7hzy5" updated="20230228174009">对固定输入变量j可以找到最优切分点s</p>
<div data-content="\hat{c_1}=ave(y_i|x_i∈R_1(j,s))  \ \ \ 和\ \ \  \hat{c_2}=ave(y_i|x_i∈R_2(j,s))" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-467y4h2" updated="20230228174009">遍历所有输入变量，找到最优的切分变量<span data-type="inline-math" data-subtype="math" data-content="j" contenteditable="false" class="render-node"></span>，构成一个对<span data-type="inline-math" data-subtype="math" data-content="(j,s)" contenteditable="false" class="render-node"></span>。依次将输入空间划分为两个区域，重复上述过程，直到满足条件后停止</p>
<h6 id="算法步骤" updated="20230228174009">算法步骤</h6>
<ul id="20230228174009-s2q057x" updated="20230228174009">
<li id="20230228174009-bzc9qnm" updated="20230228174009">
<p id="20230228174009-mdtn7pq" updated="20230228174009">依次遍历每个特征j，以及该特征的每个取值s，计算每个切分点（j,s）的损失函数，选择损失函数最小的切分点。</p>
</li>
<li id="20230228174009-9n5xmqf" updated="20230228174009">
<p id="20230228174009-8oo1qaf" updated="20230228174009">使用上步得到的切分点将当前的输入空间划分为两个部分。</p>
</li>
<li id="20230228174009-oc6r8rf" updated="20230228174009">
<p id="20230228174009-dtgrmsd" updated="20230228174009">对两个子区域递归地调用步骤1和2，直到满足停止条件。</p>
</li>
<li id="20230228174009-fwc5pc6" updated="20230228174009">
<p id="20230228174009-2cfj2jm" updated="20230228174009">将输入空间划分为M个区域，生成回归树。</p>
</li>
</ul>
<h6 id="例题-" updated="20230228174009">例题：</h6>
<p id="20230228174009-7cuoz9s" updated="20230228174009">‍</p>
<h5 id="CART剪枝" updated="20230228174009">CART剪枝</h5>
<p id="20230228174009-55sp9pt" updated="20230228174009">CART剪枝算法从“完全生长”的决策树的底端减去一些子树，使得决策树变小，模型变简单，从而能够对未知数据有更加准确的预测。</p>
<p id="20230228174009-kcr88fd" updated="20230228174009"><span data-type="strong">CART剪枝由两部份组成</span>：</p>
<ul id="20230228174009-ozyu113" updated="20230228174009">
<li id="20230228174009-1y3z9db" updated="20230228174009">
<p id="20230228174009-itf8mut" updated="20230228174009">首先从生成算法产生的决策树<span data-type="inline-math" data-subtype="math" data-content="T_o" contenteditable="false" class="render-node"></span>底端开始不断剪枝，直到<span data-type="inline-math" data-subtype="math" data-content="T_0" contenteditable="false" class="render-node"></span>的根节点，形成一个子树序列<span data-type="inline-math" data-subtype="math" data-content="\left \{ T_0 ,T_1,...,T_n \right \}" contenteditable="false" class="render-node"></span></p>
</li>
<li id="20230228174009-fs5nkvd" updated="20230228174009">
<p id="20230228174009-00s7dj9" updated="20230228174009">然后通过交叉验证法在独立的验证数据集上对子树序列进行测试，从中选择最优子树</p>
</li>
</ul>
<h6 id="剪枝" updated="20230228174009">剪枝</h6>
<p id="20230228174009-nlu7wp6" updated="20230228174009">剪枝，形成一个子树序列。在剪枝的过程中，计算子树的损失函数：</p>
<div data-content="C_α(T)=C(T)+α|T|" data-subtype="math"><div spin="1"></div></div>
<p id="20230228174009-crqpubi" updated="20230228174009">其中的参数分别代表如下含义：</p>
<ul id="20230228174009-cxm4qnq" updated="20230228174009">
<li id="20230228174009-19qf4b6" updated="20230228174009">
<p id="20230228174009-j8f2xs4" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="T" contenteditable="false" class="render-node"></span>代表任意子树</p>
</li>
<li id="20230228174009-0nu8a3o" updated="20230228174009">
<p id="20230228174009-kuarqeu" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="C(T)" contenteditable="false" class="render-node"></span>代表对训练数据集D的预测误差，如基尼系数</p>
</li>
<li id="20230228174009-buiz9cg" updated="20230228174009">
<p id="20230228174009-qc66hpp" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="|T|" contenteditable="false" class="render-node"></span>为子树叶子结点的个数</p>
</li>
<li id="20230228174009-b7vmrrr" updated="20230228174009">
<p id="20230228174009-r5j6i1d" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="α≥0" contenteditable="false" class="render-node"></span>为超参数（也叫<span data-type="inline-math" data-subtype="math" data-content="α" contenteditable="false" class="render-node"></span>为非负参数），权衡训练数据的拟合程度和模型的复杂度，<span data-type="inline-math" data-subtype="math" data-content="α|T|" contenteditable="false" class="render-node"></span>为此损失函数中的正则化项</p>
</li>
<li id="20230228174009-b3yhgnt" updated="20230228174009">
<p id="20230228174009-lxduant" updated="20230228174009"><span data-type="inline-math" data-subtype="math" data-content="C_α(T)" contenteditable="false" class="render-node"></span>代表当参数为<span data-type="inline-math" data-subtype="math" data-content="α" contenteditable="false" class="render-node"></span>的时候子树<span data-type="inline-math" data-subtype="math" data-content="T" contenteditable="false" class="render-node"></span>的整体损失</p>
</li>
</ul>
<p id="20230228174009-92fdgks" updated="20230228174009">剪枝的目标是让<span data-type="strong">损失函数最小</span>，<span data-type="inline-math" data-subtype="math" data-content="α" contenteditable="false" class="render-node"></span>作为一个惩罚项，<span data-type="inline-math" data-subtype="math" data-content="α" contenteditable="false" class="render-node"></span>越大，表示对模型复杂度的惩罚越大，也就是更倾向于选择简单的子树；<span data-type="inline-math" data-subtype="math" data-content="α" contenteditable="false" class="render-node"></span>越小，表示对模型复杂度的惩罚越小，也就是更倾向于选择复杂的子树。</p>
<p id="20230228174009-o7wfbve" updated="20230228174009">给定一个α，可以从树的叶节点向上<span data-type="strong">回缩</span>，比较剪枝前后的损失函数，如果剪枝后的损失函数更小或相等，就进行剪枝；否则就保留原来的子树。这样一直进行到根节点，就可以得到一个最优子树。</p>
<p id="20230228174009-o81rvwk" updated="20230228174009"><span data-type="strong">递归的方法对决策树进行剪枝：</span></p>
<p id="20230228174009-344woti" updated="20230228174009">首先对于惩罚项<span data-type="inline-math" data-subtype="math" data-content="α" contenteditable="false" class="render-node"></span>，令其从小增大，得到序列  <span data-type="inline-math" data-subtype="math" data-content="0=α_0<α_1<α_2<α_3<...<α_n<∞" contenteditable="false" class="render-node"></span> ，<span data-type="inline-math" data-subtype="math" data-content="α" contenteditable="false" class="render-node"></span>越小，代表着树<span data-type="inline-math" data-subtype="math" data-content="T" contenteditable="false" class="render-node"></span>越复杂，所以<span data-type="inline-math" data-subtype="math" data-content="α_0" contenteditable="false" class="render-node"></span>即是从一颗完整的树的底端开始，直到<span data-type="inline-math" data-subtype="math" data-content="α_n" contenteditable="false" class="render-node"></span>到达剪枝最终剩下的最简洁的树<span data-type="inline-math" data-subtype="math" data-content="T_k(α_{i=k})" contenteditable="false" class="render-node"></span>，所以在区间<span data-type="inline-math" data-subtype="math" data-content="[α_i,α_i+1),i=0,1,...,n" contenteditable="false" class="render-node"></span> 中，代表树<span data-type="inline-math" data-subtype="math" data-content="T" contenteditable="false" class="render-node"></span>从复杂到简单的一系列区间<span data-type="inline-math" data-subtype="math" data-content="{T_0,T_1,...,T_n}" contenteditable="false" class="render-node"></span>，也就是剪枝得到的子树序列对应着这个区间，且序列中的子树是嵌套的，很好理解，就是例如<span data-type="inline-math" data-subtype="math" data-content="α_0" contenteditable="false" class="render-node"></span>的时候树<span data-type="inline-math" data-subtype="math" data-content="T_0" contenteditable="false" class="render-node"></span>为完整的原树，对叶子结点的父结点进行考察得到了一棵子树<span data-type="inline-math" data-subtype="math" data-content="T_1" contenteditable="false" class="render-node"></span>，<span data-type="inline-math" data-subtype="math" data-content="T_1" contenteditable="false" class="render-node"></span>必定是被<span data-type="inline-math" data-subtype="math" data-content="T_0" contenteditable="false" class="render-node"></span>所嵌套的，以此类推</p>
<h6 id="交叉验证" updated="20230228174009">交叉验证</h6>
<p id="20230228174009-6oygc7p" updated="20230228174009">对剪枝完后得到的子树序列中，使用基尼指数或者是平方误差进行考察，取平方误差或基尼指数最小的决策树，当最优子树<span data-type="inline-math" data-subtype="math" data-content="T_k" contenteditable="false" class="render-node"></span>确定后，<span data-type="inline-math" data-subtype="math" data-content="α_k" contenteditable="false" class="render-node"></span>也确定了</p>
<h3 id="决策树剪枝" updated="20230228174009">决策树剪枝</h3>
<p id="20230228174009-u86gb2o" updated="20230228174009">剪枝的目的是为了避免在建树的过程中，一味地为了提高训练集的准确度而构建出复杂而在测试集中表现欠佳的模型所表现出的过拟合问题，根据奥卡姆剃刀原则，“如无必要，勿增实体”，在解释一个问题的情况下应当采用最简单而有效的方法。决策树的剪枝是通过极小化决策树整体的损失函数或代价函数来实现的。</p>
<blockquote id="20230228174009-ej7ymy9" updated="20230228174009">
<p id="20230228174009-8a0n8po" updated="20230228174009">损失函数和代价函数的区别是：损失函数是定义在单个样本上的，算的是一个样本的误差。代价函数是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。目标函数是最终需要优化的函数，它可能包含代价函数和正则化项等。在机器学习中，正则化是一种减少过拟合的技术，它通过给损失函数添加一个惩罚项来限制模型的复杂度。</p>
<p id="20230228174009-5nw0g9o" updated="20230228174009">常用的惩罚项有两种，L1正则化和L2正则化。L1正则化是指让参数向量的L1范数（即各元素绝对值之和）最小，L2正则化是指让参数向量的L2范数（即各元素平方之和再开根号）最小。</p>
<p id="20230228174009-vru9fuo" updated="20230228174009">直观地理解，L1正则化可以使得模型中一些不重要的特征系数变为0，从而达到降低模型复杂度和选择特征的目的；而L2正则化可以使得模型中所有特征系数都变小，从而减少过拟合风险。</p>
<p id="20230228174009-4btm96k" updated="20230228174009">[来源：Newbing]</p>
</blockquote>
<p id="20230228174009-4mslmt9" updated="20230228174009">‍</p>
</div>
<script src="appearance/icons/material/icon.js?2.7.6"></script>
<script src="stage/build/export/protyle-method.js?2.7.6"></script>
<script src="stage/protyle/js/lute/lute.min.js?2.7.6"></script>    
<script>
    window.siyuan = {
      config: {
        appearance: { mode: 1, codeBlockThemeDark: "base16/dracula", codeBlockThemeLight: "github" },
        editor: { 
          codeLineWrap: true,
          codeLigatures: false,
          plantUMLServePath: "https://www.plantuml.com/plantuml/svg/~1",
          codeSyntaxHighlightLineNum: true,
          katexMacros: JSON.stringify({}),
        }
      },
      languages: {copy:"复制"}
    };
    const previewElement = document.getElementById('preview');
    Protyle.highlightRender(previewElement, "stage/protyle");
    Protyle.mathRender(previewElement, "stage/protyle", false);
    Protyle.mermaidRender(previewElement, "stage/protyle");
    Protyle.flowchartRender(previewElement, "stage/protyle");
    Protyle.graphvizRender(previewElement, "stage/protyle");
    Protyle.chartRender(previewElement, "stage/protyle");
    Protyle.mindmapRender(previewElement, "stage/protyle");
    Protyle.abcRender(previewElement, "stage/protyle");
    Protyle.plantumlRender(previewElement, "stage/protyle");
    document.querySelectorAll(".protyle-action__copy").forEach((item) => {
      item.addEventListener("click", (event) => {
            navigator.clipboard.writeText(item.parentElement.nextElementSibling.textContent.trimEnd());
            event.preventDefault();
            event.stopPropagation();
      })
    });
</script></body></html>